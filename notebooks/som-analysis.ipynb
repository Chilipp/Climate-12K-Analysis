{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraction of temperature data out of the Temperature12K LiPD files\n",
    "\n",
    "This notebook extracts the temperature data of all temperature series in the Temperature12K database and exports them in a tab-separated file. To get the latest version of the data, just click on *Cell* &rarr; *Run all*. When the notebook is finished (i.e. if you see a table [at the bottom](#final)), you can download the temperature data [here](../data/binned-temperature-data.tsv).\n",
    "\n",
    "This notebook downloads the database from http://lipdverse.org/globalHolocene/current_version, based on the version you specify in the `db_version` variable (see below). It has been developed by Philipp Sommer (philipp.sommer@unil.ch), please do not hesitate to get in touch if you run into any problems.\n",
    "\n",
    "**Things you might want to adapt:**\n",
    "\n",
    "- the database version string (`db_version`, see [here](#db_version))\n",
    "- the `binwidth` (by default 100, see [here](#binwidth)). We have to make averages over the time series in order to put everything together\n",
    "- the records you want to download (see [here](#filter))\n",
    "- the meta data for the temperature export (see [here](#meta-cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Unable to import required dependencies:\nnumpy: Something is wrong with the numpy installation. While importing we detected an older version of numpy in ['/Users/psommer/miniconda/envs/temperature12k/lib/python3.7/site-packages/numpy']. One method of fixing this is to repeatedly uninstall numpy until none is found, then reinstall this version.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-4e47d3f8a1fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlipd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcontextlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/temperature12k/lib/python3.7/site-packages/pandas/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmissing_dependencies\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     raise ImportError(\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0;34m\"Unable to import required dependencies:\\n\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_dependencies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     )\n\u001b[1;32m     19\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mhard_dependencies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdependency\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmissing_dependencies\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: Unable to import required dependencies:\nnumpy: Something is wrong with the numpy installation. While importing we detected an older version of numpy in ['/Users/psommer/miniconda/envs/temperature12k/lib/python3.7/site-packages/numpy']. One method of fixing this is to repeatedly uninstall numpy until none is found, then reinstall this version."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import lipd\n",
    "import numpy as np\n",
    "import contextlib\n",
    "import os\n",
    "import os.path as osp\n",
    "from urllib import request\n",
    "import zipfile\n",
    "import re\n",
    "import xarray as xr\n",
    "import psyplot.project as psy\n",
    "import sys "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=binwidth></a>We have to specify the bin widths in years. Each timeseries will be averaged into bins with this length in order to merge them all together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binwidth = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=db_version></a>Read in the LipD data from http://lipdverse.org/globalHolocene/current_version\n",
    "\n",
    "You should set the latest version here manually!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_version = '0_30_1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "if not osp.exists('../data'):\n",
    "    os.makedirs('../data')\n",
    "zipped = f'globalHolocene{db_version}.zip'\n",
    "uri = f'http://lipdverse.org/globalHolocene/{db_version}/{zipped}'\n",
    "target = osp.join('../data', zipped)\n",
    "print('downloading ' + uri)\n",
    "request.urlretrieve(uri, target)\n",
    "with zipfile.ZipFile(target) as f:\n",
    "    f.extractall('../data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextlib.contextmanager\n",
    "def remember_cwd():\n",
    "    \"\"\"Context manager to switch back to the current working directory\n",
    "\n",
    "    Usage::\n",
    "\n",
    "        with remember_cwd():\n",
    "            os.chdir('test')\n",
    "            print(os.getcwd())  # test\n",
    "        print(os.getcwd())      # test/..\"\"\"\n",
    "    curdir = os.getcwd()\n",
    "    try:\n",
    "        yield\n",
    "    except:\n",
    "        raise\n",
    "    finally:\n",
    "        os.chdir(curdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# with remember_cwd():\n",
    "#     os.chdir('../data/')\n",
    "#     data = lipd.readLipd('.')\n",
    "import pickle\n",
    "with open('../data/lipds.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract all the paleoData series from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "all_series = lipd.extractTs(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract only the temperature series with units in degrees Celsius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_ts_temp12k = lipd.filterTs(all_series,'paleoData_inCompilation == Temp12k')\n",
    "filtered_ts_useinglobal = lipd.filterTs(filtered_ts_temp12k,'paleoData_useInGlobalTemperatureAnalysis == TRUE')\n",
    "temperatures = lipd.filterTs(filtered_ts_useinglobal,'paleoData_units == degC')\n",
    "sorted(temperatures[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annual = [d for d in temperatures if d['paleoData_interpretation'][0]['seasonalityGeneral'] == 'annual']\n",
    "summer = [d for d in temperatures if d['paleoData_interpretation'][0]['seasonalityGeneral'].startswith('summer')]\n",
    "winter = [d for d in temperatures if d['paleoData_interpretation'][0]['seasonalityGeneral'].startswith('winter')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(d.get('paleoData_interpretation', [{}])[0].get('seasonalityGeneral', '') for d in temperatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='meta_cols'></a>Transform the temperatures into pandas series. The `meta_cols` is the meta data that should be available as column in the data frame and has to match one of the keys in the previous list. The `meta_names` then specifies how the corresponding field from `meta_cols` appears in the final data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "season_patt = re.compile(r'annual|winter|summer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_cols = ['geo_meanLon', 'geo_meanLat', 'dataSetName', \n",
    "             'TSid', 'paleoData_variableName', 'paleoData_proxy', 'archiveType', 'paleoData_datum']\n",
    "meta_names = ['lon', 'lat', 'dataSetName', 'TSid', 'variableName', 'proxy', 'archiveType', 'datum', 'seasonality']\n",
    "\n",
    "series = [\n",
    "    pd.Series(\n",
    "        np.asarray(d['paleoData_values'], dtype=float),\n",
    "        index=np.asarray(d['age'], dtype=float),\n",
    "        name=tuple(d.get(name, np.nan) for name in meta_cols) + (\n",
    "            season_patt.match(d['paleoData_interpretation'][0]['seasonalityGeneral']).group(), ))\n",
    "    for d in temperatures if 'age' in d]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and bin them based on centennial scales and merge them into one single dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def age_grouper(age):\n",
    "    \"\"\"Bin age to centuries\"\"\"\n",
    "    return age - (age % binwidth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binned = [s.groupby(age_grouper).mean().sort_index() for s in series]\n",
    "\n",
    "merged = binned[0].to_frame()\n",
    "merged.columns.names = meta_names\n",
    "\n",
    "for s in binned[1:]:\n",
    "    merged = merged.merge(\n",
    "        (s if s.name[-2] == 'anom' else s - s.iloc[0]).to_frame(), left_index=True, right_index=True,\n",
    "                          how='outer')\n",
    "    \n",
    "merged = merged.T.loc[:, -100:12000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annual = merged[merged.index.get_level_values(-1) == 'annual']\n",
    "summer = merged[merged.index.get_level_values(-1) == 'summer']\n",
    "winter = merged[merged.index.get_level_values(-1) == 'winter']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lon = np.arange(-180+0.25, 180, 0.5)\n",
    "lat = np.arange(-90 + 0.25, 90, 0.5)\n",
    "points = np.dstack(np.meshgrid(lon, lat)).reshape(-1, 2)\n",
    "gridded = xr.DataArray(np.zeros((3, merged.shape[1], len(lat), len(lon))), \n",
    "                       coords={'season': ['annual', 'summer', 'winter'],\n",
    "                               'time': merged.columns,\n",
    "                               'lat': lat, 'lon': lon}, \n",
    "                       dims=('season', 'time', 'lat', 'lon'),\n",
    "                       name='temperature')\n",
    "gridded.values[:] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_annual = annual.groupby(lambda t: lat.searchsorted(t[0]) * lon.searchsorted(t[1])).mean()\n",
    "mean_winter = winter.groupby(lambda t: lat.searchsorted(t[0]) * lon.searchsorted(t[1])).mean()\n",
    "mean_summer = summer.groupby(lambda t: lat.searchsorted(t[0]) * lon.searchsorted(t[1])).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in mean_annual.iterrows():\n",
    "    lon, lat = points[idx]\n",
    "    gridded.loc[{'season': 'annual', 'time': mean_annual.columns, 'lon': lon, 'lat': lat}] = row.values\n",
    "for idx, row in mean_winter.iterrows():\n",
    "    lon, lat = points[idx]\n",
    "    gridded.loc[{'season': 'winter', 'time': mean_winter.columns, 'lon': lon, 'lat': lat}] = row.values\n",
    "for idx, row in mean_summer.iterrows():\n",
    "    lon, lat = points[idx]\n",
    "    gridded.loc[{'season': 'summer', 'time': mean_summer.columns, 'lon': lon, 'lat': lat}] = row.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridded[0].psy.plot.fldmean();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython\n",
    "\n",
    "import rpy2.robjects.numpy2ri\n",
    "rpy2.robjects.numpy2ri.activate()\n",
    "\n",
    "%R library(kohonen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = mean_annual.values\n",
    "som = MiniSom(6, 6, data.shape[1], sigma=2., learning_rate=0.5)\n",
    "som.pca_weights_init(data)\n",
    "print(\"Training...\")\n",
    "som.train_batch(data, 50000, verbose=True)  # random training\n",
    "print(\"\\n...ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridded[0].to_dataset().psy.plot.mapplot(time=list(range(0, 100, 10)), cmap='RdBu_r', bounds='roundedsym');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annual.index.get_level_values(1).min(),annual.index.get_level_values(1).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "merged.to_csv('../data/binned-temperature-data.tsv', '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='final'></a>That's it! If the notebook has finished, you can download the temperature data [here](../data/binned-temperature-data.tsv) and the corresponding meta data [here](../data/meta.tsv) as tab-separated files.\n",
    "\n",
    "So let's have a look into the final temperature data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.loc[merged.iloc[:, 0].notnull()]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "temperature12k",
   "language": "python",
   "name": "climate12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
